{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import mca\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier, plot_importance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000320 entries, 0 to 2000319\n",
      "Data columns (total 4 columns):\n",
      "hpg_store_id        object\n",
      "visit_datetime      object\n",
      "reserve_datetime    object\n",
      "reserve_visitors    int64\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#Split the file since its too big for github, extract the file outside of .git repository\n",
    "\"\"\"\n",
    "hpg_res = pd.read_csv('C:\\\\Users\\\\mingt\\\\Downloads\\\\hpg_reserve.csv\\\\hpg_reserve.csv')\n",
    "hpg_res.info()\n",
    "df1 = hpg_res.iloc[0:100160]\n",
    "df2 = hpg_res.iloc[100161:200320]\n",
    "df1.to_csv('hpg_reserve1.csv')\n",
    "df2.to_csv('hpg_reserve2.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "air_reserve = pd.read_csv('air_reserve.csv')\n",
    "air_store_info= pd.read_csv('air_store_info.csv')\n",
    "air_visit_data = pd.read_csv('air_visit_data.csv')\n",
    "date_info = pd.read_csv('date_info.csv')\n",
    "hpg_store_info = pd.read_csv('hpg_store_info.csv')\n",
    "store_id_relation = pd.read_csv('store_id_relation.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#concat files back after its been uploaded on github\n",
    "hpg_reserve1 = pd.read_csv('hpg_reserve1.csv')\n",
    "hpg_reserve2 = pd.read_csv('hpg_reserve2.csv')\n",
    "\n",
    "hpg_reserve = pd.concat([hpg_reserve1, hpg_reserve2])\n",
    "hpg_reserve['visit_datetime'] = pd.to_datetime(hpg_reserve['visit_datetime'])\n",
    "hpg_reserve['reserve_datetime'] = pd.to_datetime(hpg_reserve['reserve_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_combined = pd.merge(air_reserve, air_store_info, on='air_store_id', how='outer')\n",
    "hpg_combined = pd.merge(hpg_reserve, hpg_store_info, on='hpg_store_id', how='left')\n",
    "\n",
    "df = store_id_relation.merge(hpg_combined, on='hpg_store_id', how='left')\n",
    "df2 = air_combined.merge(df, on='air_store_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary key on column: 'air_store_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime_x</th>\n",
       "      <th>reserve_datetime_x</th>\n",
       "      <th>reserve_visitors_x</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude_x</th>\n",
       "      <th>longitude_x</th>\n",
       "      <th>hpg_store_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>visit_datetime_y</th>\n",
       "      <th>reserve_datetime_y</th>\n",
       "      <th>reserve_visitors_y</th>\n",
       "      <th>hpg_genre_name</th>\n",
       "      <th>hpg_area_name</th>\n",
       "      <th>latitude_y</th>\n",
       "      <th>longitude_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Japanese food</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Japanese food</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-02 18:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Japanese food</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-02 21:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Japanese food</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-08 21:00:00</td>\n",
       "      <td>2016-01-04 20:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Japanese food</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id     visit_datetime_x   reserve_datetime_x  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_877f79706adbfb06  2016-01-01 20:00:00  2016-01-01 16:00:00   \n",
       "2  air_877f79706adbfb06  2016-01-02 18:00:00  2016-01-01 16:00:00   \n",
       "3  air_877f79706adbfb06  2016-01-02 21:00:00  2016-01-01 16:00:00   \n",
       "4  air_877f79706adbfb06  2016-01-08 21:00:00  2016-01-04 20:00:00   \n",
       "\n",
       "   reserve_visitors_x air_genre_name                 air_area_name  \\\n",
       "0                 1.0  Japanese food  Tōkyō-to Minato-ku Shibakōen   \n",
       "1                 2.0  Japanese food  Tōkyō-to Minato-ku Shibakōen   \n",
       "2                 2.0  Japanese food  Tōkyō-to Minato-ku Shibakōen   \n",
       "3                 2.0  Japanese food  Tōkyō-to Minato-ku Shibakōen   \n",
       "4                 2.0  Japanese food  Tōkyō-to Minato-ku Shibakōen   \n",
       "\n",
       "   latitude_x  longitude_x hpg_store_id  Unnamed: 0 visit_datetime_y  \\\n",
       "0   35.658068   139.751599          NaN         NaN              NaT   \n",
       "1   35.658068   139.751599          NaN         NaN              NaT   \n",
       "2   35.658068   139.751599          NaN         NaN              NaT   \n",
       "3   35.658068   139.751599          NaN         NaN              NaT   \n",
       "4   35.658068   139.751599          NaN         NaN              NaT   \n",
       "\n",
       "  reserve_datetime_y  reserve_visitors_y hpg_genre_name hpg_area_name  \\\n",
       "0                NaT                 NaN            NaN           NaN   \n",
       "1                NaT                 NaN            NaN           NaN   \n",
       "2                NaT                 NaN            NaN           NaN   \n",
       "3                NaT                 NaN            NaN           NaN   \n",
       "4                NaT                 NaN            NaN           NaN   \n",
       "\n",
       "   latitude_y  longitude_y  \n",
       "0         NaN          NaN  \n",
       "1         NaN          NaN  \n",
       "2         NaN          NaN  \n",
       "3         NaN          NaN  \n",
       "4         NaN          NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11171047 entries in 'air_store_id', with 829 unique restaurants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1171047 entries, 0 to 1171046\n",
      "Data columns (total 17 columns):\n",
      "air_store_id          1171047 non-null object\n",
      "visit_datetime_x      1170265 non-null object\n",
      "reserve_datetime_x    1170265 non-null object\n",
      "reserve_visitors_x    1170265 non-null float64\n",
      "air_genre_name        1171047 non-null object\n",
      "air_area_name         1171047 non-null object\n",
      "latitude_x            1171047 non-null float64\n",
      "longitude_x           1171047 non-null float64\n",
      "hpg_store_id          1114437 non-null object\n",
      "Unnamed: 0            1112519 non-null float64\n",
      "visit_datetime_y      1112519 non-null datetime64[ns]\n",
      "reserve_datetime_y    1112519 non-null datetime64[ns]\n",
      "reserve_visitors_y    1112519 non-null float64\n",
      "hpg_genre_name        451960 non-null object\n",
      "hpg_area_name         451960 non-null object\n",
      "latitude_y            451960 non-null float64\n",
      "longitude_y           451960 non-null float64\n",
      "dtypes: datetime64[ns](2), float64(7), object(8)\n",
      "memory usage: 160.8+ MB\n",
      "None\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "print(df2.info())\n",
    "print(len(df2['air_store_id'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lbl = LabelEncoder()\n",
    "\n",
    "\n",
    "df2['latitude'] = df2['latitude_x'].astype(str)\n",
    "df2['longitude'] = df2['longitude_x'].astype(str)\n",
    "\n",
    "date_info['calendar_date'] = pd.to_datetime(date_info['calendar_date']).dt.date.astype(str)\n",
    "#date_info['holiday_flg'] = date_info['holiday_flg'].map({1: 'Yes', 0: 'No'})\n",
    "date_info['MTWTF'] = date_info['day_of_week'].map({'Monday': 1, \n",
    "                                                   'Tuesday': 2, \n",
    "                                                   'Wednesday': 3, \n",
    "                                                   'Thursday': 4, \n",
    "                                                   'Friday': 5,\n",
    "                                                   'Saturday': 6, \n",
    "                                                   'Sunday': 7})\n",
    "\n",
    "date_info['weekend_or_weekday'] = date_info['day_of_week'].map({'Monday': 0, \n",
    "                                                                'Tuesday': 0, \n",
    "                                                                'Wednesday': 0, \n",
    "                                                                'Thursday': 0, \n",
    "                                                                'Friday': 0,\n",
    "                                                                'Saturday': 1, \n",
    "                                                                'Sunday': 1})\n",
    "\n",
    "\n",
    "date_info2 = date_info.drop(['day_of_week'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_store = sample_submission['id'].apply(lambda x: str(x).split('_', 2)[:2])\n",
    "sub_dates = pd.to_datetime(sample_submission['id'].apply(lambda x: str(x).split('_', 2)[2]).rename('Date'))\n",
    "sub_stores = pd.Series(['_'.join(x) for x in sub_store]).rename('air_store_id')\n",
    "\n",
    "sub_dt = pd.DataFrame({\n",
    "        'air_store_id': sub_stores,\n",
    "        'date': sub_dates.dt.date.astype(str),\n",
    "        #'year': sub_dates.dt.year,\n",
    "        'month': sub_dates.dt.month,\n",
    "        'day': sub_dates.dt.day })\n",
    "\n",
    "sub_df = pd.concat([sample_submission, sub_dt], axis=1)\n",
    "#sub_df['weekend_or_weekday'] = sub_df['weekend_or_weekday'].apply(LabelEncoder().fit_transform)\n",
    "sub_df2 = sub_df.merge(date_info2, left_on= sub_df['date'], right_on=date_info['calendar_date'])\n",
    "sub_df3 = sub_df2.drop(['id', 'calendar_date', 'date'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master_col = df2[['air_store_id']]\n",
    "\n",
    "a = pd.to_datetime(df2['visit_datetime_x'])\n",
    "#b = pd.to_datetime(df2['reserve_datetime_x'])\n",
    "#c = pd.to_datetime(df2['visit_datetime_y'])\n",
    "#d = pd.to_datetime(df2['reserve_datetime_y'])\n",
    "\n",
    "datetime_df =pd.DataFrame({\n",
    "        'air_visit_date': a.dt.date.astype(str),\n",
    "        #'year': a.dt.year,\n",
    "        'month': a.dt.month,\n",
    "        'day': a.dt.day,\n",
    "        \n",
    "        #'air_visit_hour': a.dt.hour,\n",
    "        #'air_visit_date': a.dt.date,\n",
    "        #'air_visit_year': b.dt.year,\n",
    "        \n",
    "        #'air_reserve_month': b.dt.month,\n",
    "        #'air_reserve_day': b.dt.day,\n",
    "        #'air_reserve_hour': b.dt.hour,\n",
    "         \n",
    "        #'hpg_visit_date': c.dt.date,\n",
    "        #'hpg_visit_year': c.dt.year,\n",
    "        #'hpg_visit_month': c.dt.month,\n",
    "        #'hpg_visit_day': c.dt.day,\n",
    "        #'hpg_visit_hour': c.dt.hour,\n",
    "        \n",
    "        #'hpg_reserve_date': d.dt.date,\n",
    "        #'hpg_reserve_year': d.dt.year,\n",
    "        #'hpg_reserve_month': d.dt.month,\n",
    "        #'hpg_reserve_day': d.dt.day,\n",
    "        #'hpg_reserve_hour': d.dt.hour        \n",
    "    }).fillna(0)\n",
    "\n",
    "datetime_df2 = datetime_df.merge(date_info, left_on=datetime_df['air_visit_date'], \n",
    "                                 right_on=date_info['calendar_date'])\n",
    "\n",
    "\n",
    "categorical_df = pd.concat([master_col, df2[['air_genre_name','air_area_name','latitude','longitude',\n",
    "                      'hpg_genre_name','hpg_area_name']].fillna('None_Stated').apply(LabelEncoder().fit_transform)], axis=1)\n",
    "\n",
    "sub_df4 = sub_df3.merge(categorical_df, left_on=sub_df3['air_store_id'], right_on=categorical_df['air_store_id'])  \n",
    "#categorical_dummy = pd.get_dummies(df2[['air_genre_name','air_area_name','latitude','longitude', 'hpg_genre_name','hpg_area_name']].fillna('None_Stated'))\n",
    "\n",
    "combined_visitors = pd.Series(df2['reserve_visitors_x'].fillna(0) + df2['reserve_visitors_y'].fillna(0)).rename('visitors')\n",
    "\n",
    "\n",
    "feats = pd.concat([datetime_df2, combined_visitors, categorical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = lbl.fit_transform(feats['air_store_id'].append(sub_df4['air_store_id_x']))\n",
    "feats['air_store_id_num'] = pd.Series(ids[:1171046])\n",
    "sub_df4['air_store_id_num'] = pd.Series(ids[1171047:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats2 = feats.drop(['air_store_id', 'air_visit_date', 'calendar_date', 'day_of_week'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_df5 = sub_df4.drop(['air_store_id_x', 'air_store_id_y', ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_df6 = sub_df5.reindex(columns=list(feats2.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feats2, feats2['visitors'], test_size=0.1, random_state=7)\n",
    "\n",
    "xgbR = XGBRegressor(learning_rate=0.1, \n",
    "                   objective='reg:linear')\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.1, \n",
    "                   objective='reg:linear')\n",
    "\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000445210602354\n"
     ]
    }
   ],
   "source": [
    "pred = xgb.predict(X_test)\n",
    "mse = mean_squared_error(y_test, pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-a6c7c60c489a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_df6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "xgb.predict(sub_df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis_by_store = feats2['visitors'].groupby(feats2['air_store_id_num']).describe()\n",
    "vis_by_dow = feats2['visitors'].groupby(feats2['MTWTF']).describe()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
